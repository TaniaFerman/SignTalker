![Alt text](images/signtalkerlogo.png)

##### [Department of Computer Science - University of Victoria](http://www.csc.uvic.ca/)
##### [CSC 485E + SENG 480B](https://heat.csc.uvic.ca/coview/outline/2016/Fall/CSC/485E), 2016, Fall Semester

### Idea Proposal

We are proposing a mobile app that will act as a tool to enable those in the deaf community to have a more dynamic communications with non-deaf people.  For those who are able to lip-read but are not capable of speech are limited to using text-to-speech functions.  This is a disengagement as the listener must wait for the finish typing out a sentence(s) on a mobile keyboard.  Our proposed solution is to use the camera on an Android device and existing gesture recognition and text-to-speech technologies to automatically translate the American Sign Language (ASL) alphabet into speech.

The user would place their hand a comfortable distance above the phone (for example, while the device lays flat on a table) with the app open.  Prior to that, they will have performed a set of calibration tests to customize the performance of the app to their hand.  They will fingerspell like normal and tap the phone screen once they finish a word.  The interpreted word is then fed through the Google Text Prediction API to remove false-positive results and feed to a text-to-speech API.  Thus, allowing the user to to communicate verbally in near real-time.

### Idea Proposal Video

(https://youtu.be/yspqSYtJCss)

### Members:

- Amanda Dash [adash42@uvic.ca]
- Nora Huang [norah@uvic.ca]
- Dany Cabrera [dcabrera@uvic.ca]
- Tristan Partridge [tpart526@uvic.ca]
- Maria Ferman [mfermang@uvic.ca]

### SignTalker contact email:

- SignTalkerASL@gmail.com