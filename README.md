<!-- ![Alt text](../html/images/SignCoachLogo.png) -->
![Alt text](images/SignCoachLogo.png)

##### [Department of Computer Science - University of Victoria](http://www.csc.uvic.ca/)
##### [CSC 485E + SENG 480B](https://heat.csc.uvic.ca/coview/outline/2016/Fall/CSC/485E), 2016, Fall Semester

### Idea Proposal

We are proposing a mobile app that will act as an educational tool for learning American Sign Language (ASL). The existing ASL educational apps only shows flash cards, and users cannot check if their hand position is accurate.    

In our project we will use the camera on an Android device and existing computer vision machine learning to allow users to learn the ASL alphabet. The user would place her or his hand in a comfortable distance above the phone with the app open. Our mobile app will allow users to have an interactive learning, and to have an automatic feedback about their signing.

### Interactive Prototype

https://projects.invisionapp.com/share/S49501VVU#/screens/201079137

### Members:

- Amanda Dash [adash42@uvic.ca]
- Nora Huang [norah@uvic.ca]
- Dany Cabrera [dcabrera@uvic.ca]
- Tristan Partridge [tpart526@uvic.ca]
- Maria Ferman [mfermang@uvic.ca]

### SignCoach contact email:

- SignCoachASL@gmail.com


### [ASL Contact Information](https://github.com/TaniaFerman/SignTalker/blob/master/docs/findingASLusers.md)

### [ASL Interpreters](https://github.com/TaniaFerman/SignTalker/blob/master/docs/ASLInterpreters.md)


